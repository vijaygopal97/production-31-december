# üöÄ LOAD BALANCER SETUP REPORT
**Date:** December 30, 2025  
**Setup Type:** Industry-Level Load Balancing  
**Status:** ‚úÖ ACTIVE

---

## üìä ARCHITECTURE OVERVIEW

### Server Configuration

#### **Current Server (Primary)**
- **IP:** 13.202.181.167 (172.31.43.71)
- **Type:** Current production server
- **CPU:** 8 cores
- **RAM:** 30GB
- **PM2 Instances:** 5 backend instances
- **Port:** 5000
- **Weight:** 1

#### **Server 1 (c6i.4xlarge)**
- **IP:** 13.233.231.180
- **Type:** High-performance server
- **CPU:** 16 cores
- **RAM:** 30GB (21GB free)
- **PM2 Instances:** 5 backend instances
- **Port:** 5000
- **Weight:** 2 (receives 2x traffic due to higher capacity)

#### **Server 2 (t2.xlarge)**
- **IP:** 3.110.105.59
- **Status:** ‚ö†Ô∏è Not accessible (Security Group configuration needed)
- **Type:** Secondary server
- **CPU:** 4 cores
- **RAM:** 16GB
- **Weight:** 1 (will be added when accessible)

---

## üîß CONFIGURATION DETAILS

### Load Balancing Algorithm
- **Method:** `least_conn` (Least Connections)
- **Rationale:** Distributes traffic based on current connection count, ensuring optimal resource utilization

### Health Checks
- **Endpoint:** `/health`
- **Max Failures:** 3
- **Fail Timeout:** 30 seconds
- **Keepalive:** 32 connections

### Nginx Configuration
- **Upstream Block:** Defined in `/etc/nginx/nginx.conf`
- **Load Balancer Config:** `/etc/nginx/sites-available/opine-loadbalancer`
- **Frontend Config:** Updated `/etc/nginx/sites-available/convo.convergentview.com` to use load balancer

### Health Check Endpoint
```json
{
  "status": "healthy",
  "timestamp": "2025-12-30T22:13:43.514Z",
  "uptime": 24.18,
  "memory": {
    "used": 41,
    "total": 44,
    "rss": 106
  },
  "database": "connected",
  "server": "13.202.181.167"
}
```

---

## ‚úÖ IMPLEMENTATION STEPS COMPLETED

1. ‚úÖ Added health check endpoint (`/health`) to backend
2. ‚úÖ Updated Server 1 with health check endpoint
3. ‚úÖ Configured Nginx upstream block in main config
4. ‚úÖ Created load balancer configuration
5. ‚úÖ Updated frontend config to use load balancer
6. ‚úÖ Tested connectivity between servers
7. ‚úÖ Verified load distribution

---

## üìà EXPECTED IMPROVEMENTS

### Capacity Increase
- **Before:** Single server handling all traffic (~30-50 concurrent users)
- **After:** 2 servers (3 when Server 2 is added)
  - **Current Capacity:** ~100-150 concurrent users
  - **With Server 2:** ~150-200 concurrent users

### Performance Improvements
- **Response Time:** Reduced by ~40-50% (load distributed)
- **CPU Usage:** Reduced by ~50% per server
- **Memory Usage:** More headroom per server
- **Availability:** High availability (if one server fails, others continue)

### Traffic Distribution
- **Current Server:** ~33% of traffic (weight: 1)
- **Server 1 (c6i.4xlarge):** ~67% of traffic (weight: 2)
- **Server 2 (t2.xlarge):** Will receive ~33% when added

---

## üîç MONITORING

### Health Check Commands
```bash
# Check load balancer status
curl http://localhost/health

# Check Server 1 directly
curl http://13.233.231.180:5000/health

# Monitor load distribution
for i in {1..20}; do curl -s http://localhost/health | jq -r '.server'; done | sort | uniq -c
```

### Nginx Logs
- **Access Log:** `/var/log/nginx/opine-access.log`
- **Error Log:** `/var/log/nginx/opine-error.log`

### PM2 Monitoring
```bash
# Current server
pm2 monit

# Server 1
ssh -i /var/www/opine/Convergent-New.pem ubuntu@13.233.231.180 "pm2 monit"
```

---

## ‚ö†Ô∏è SERVER 2 SETUP (PENDING)

### Requirements
1. **Security Group Configuration:**
   - Allow inbound traffic on port 5000 from current server IP (13.202.181.167)
   - Allow inbound traffic on port 22 (SSH) from current server

2. **Server Setup Steps:**
   ```bash
   # 1. Clone code repository
   cd /var/www
   git clone <repository-url> opine
   
   # 2. Install dependencies
   cd opine/backend
   npm install
   
   # 3. Configure environment variables
   cp .env.example .env
   # Edit .env with MongoDB URI and other settings
   
   # 4. Start with PM2
   pm2 start server.js --name opine-backend -i 5
   pm2 save
   ```

3. **Add to Load Balancer:**
   - Uncomment Server 2 line in `/etc/nginx/nginx.conf` upstream block
   - Reload Nginx: `sudo systemctl reload nginx`

---

## üõ†Ô∏è MAINTENANCE COMMANDS

### Update Code on All Servers
```bash
# Current server
cd /var/www/opine && git pull && pm2 restart opine-backend

# Server 1
ssh -i /var/www/opine/Convergent-New.pem ubuntu@13.233.231.180 "cd /var/www/opine && git pull && pm2 restart opine-backend"

# Server 2 (when accessible)
ssh -i /var/www/opine/Convergent-New.pem ubuntu@3.110.105.59 "cd /var/www/opine && git pull && pm2 restart opine-backend"
```

### Reload Nginx Configuration
```bash
sudo nginx -t  # Test configuration
sudo systemctl reload nginx  # Reload without downtime
```

### Check Load Balancer Status
```bash
# Check upstream servers
sudo nginx -T 2>/dev/null | grep -A 10 "upstream opine_backend"

# Check active connections
sudo netstat -an | grep :5000 | wc -l
```

---

## üìä PERFORMANCE METRICS

### Before Load Balancing
- **Single Server CPU:** 100% (MongoDB bottleneck)
- **Response Time (P95):** 18.8 seconds
- **Concurrent Users:** ~30-50
- **Memory Usage:** 95.54% (critical)
- **Crash Rate:** 1,232 restarts

### After Load Balancing (Expected)
- **Per Server CPU:** ~50-60% (distributed load)
- **Response Time (P95):** < 2 seconds
- **Concurrent Users:** ~100-150
- **Memory Usage:** ~60-70% (healthy)
- **Crash Rate:** < 10 per day

---

## üîê SECURITY NOTES

1. **SSH Key:** `/var/www/opine/Convergent-New.pem` (permissions: 600)
2. **Firewall:** Ensure security groups allow inter-server communication
3. **MongoDB:** All servers connect to same MongoDB instance
4. **SSL/TLS:** Frontend uses HTTPS, backend API through load balancer

---

## ‚úÖ VERIFICATION CHECKLIST

- [x] Health check endpoint working on all servers
- [x] Nginx load balancer configured
- [x] Upstream servers accessible
- [x] Frontend routing through load balancer
- [x] Load distribution tested
- [ ] Server 2 configured (pending security group)
- [ ] Performance monitoring setup
- [ ] Alerting configured

---

## üéØ NEXT STEPS

1. **Immediate:**
   - Monitor load distribution for 24 hours
   - Verify no errors in logs
   - Test with real user traffic

2. **Short-term:**
   - Configure Server 2 security group
   - Add Server 2 to load balancer
   - Set up monitoring dashboard

3. **Long-term:**
   - Implement Redis caching layer
   - Add database read replicas
   - Set up automated scaling

---

## üìù NOTES

- **Development:** Code remains on current server for development
- **Deployment:** Use git pull on all servers for updates
- **Database:** Shared MongoDB connection (ensure connection pool is sufficient)
- **Sessions:** Consider Redis for session storage in multi-server setup

---

**Setup Completed By:** AI Assistant  
**Date:** December 30, 2025  
**Status:** ‚úÖ Production Ready (2 servers active, 1 pending)






